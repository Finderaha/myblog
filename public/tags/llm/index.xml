<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on Finder</title>
    <link>http://localhost:1313/tags/llm/</link>
    <description>Recent content in LLM on Finder</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Oct 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>生成式AI：原理、影响和应用</title>
      <link>http://localhost:1313/cn/2025/10/29/generative-ai-for-everyone/</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/cn/2025/10/29/generative-ai-for-everyone/</guid>
      <description>该系列是我学习Generative AI for Everyone&#xD;课程的笔记，也是系统学习AI课程的第一站。&#xA;概论 自从2022年11月OpenAI发布ChatGPT以来，**生成式AI (Gen AI)**已成为一股强大的颠覆性技术，正改变许多人的学习和工作方式。它被认为将赋能许多人，提高生产力，并可能为全球经济增长做出重大贡献。据麦肯锡估计，Gen AI每年可为经济增加2.6万亿至4.4万亿美元。然而，该技术也引发了对自动化导致失业的担忧。&#xA;生成式AI指的是能够生成高质量内容的AI系统，主要内容类型包括文本、图像和音频。尽管目前最大的影响体现在文本生成领域（如ChatGPT、Bard、Bing Chat），但它也能够生成精美或超逼真的图像，以及进行音频（声音克隆）甚至视频克隆。&#xA;Gen AI的出现，使得许多AI应用的构建比以往更容易、更便宜，促使AI产品和服务数量激增。除了面向消费者的应用外，它作为开发者工具的潜力在长期来看可能更具影响力。&#xA;根据您提供的新视频片段“W1 2 how generative ai work”的文字稿，以下是该视频内容的总结：&#xA;一、 生成式AI在AI格局中的定位 生成式AI（Generative AI）的能力，例如ChatGPT和Bard等系统生成文本的能力，看似具有魔力，代表了AI技术的一大进步。AI可以被视为一系列工具的集合。在当今最重要的AI工具中，包括监督学习（Supervised Learning, SL）和生成式AI。&#xA;二、 监督学习的工作机制 监督学习是一种技术，擅长于“贴标签”（labeling things），它在给定输入A时，能够生成相应的输出B。&#xA;监督学习的典型应用示例包括：&#xA;垃圾邮件过滤： 输入A为一封电子邮件，输出B为判断它是否为垃圾邮件（0或1）。 在线广告： 根据广告和用户信息（A），预测用户是否可能点击该广告（B）。 自动驾驶： 接收汽车前方的图像和雷达信息（A），标记出其他车辆的位置（B）。 医疗诊断： 输入医疗X光片（A），输出医疗诊断（B）。 缺陷检测： 拍摄组装线上手机的图片（A），检查是否有划痕或其他缺陷（B）。 语音识别： 输入音频（A），输出文本转录（B）。 情绪分析： 阅读业务或产品的评论（A），标记其是积极还是消极的情绪（B），这对声誉监控很有用。 三、 大规模监督学习奠定基础 大约2010年至2020年是大规模监督学习发展的十年。研究人员发现，对于许多应用而言，即使输入更多数据，如果模型较小，性能提升也有限。然而，如果训练非常大的AI模型，即使用非常快、非常强大的计算机和大量内存，并且输入更多数据，那么性能就会持续提升。正是这种用于贴标签的超大型模型的理念，为现代生成式AI奠定了基础。&#xA;四、 大型语言模型（LLMs）如何生成文本 大型语言模型（LLMs）是生成式AI生成文本的技术。LLMs的工作原理是通过使用监督学习技术反复预测下一个词。&#xA;训练数据： LLMs通过阅读互联网上数千亿甚至数万亿个词语来学习。 预测机制： 训练过程将句子转化为大量数据点（输入A和输出B）。例如，系统学习到“我最喜欢的食物是” (A) 之后的下一个词可能是“百吉饼” (B)。 文本生成： 当系统在海量数据上训练成一个非常大的AI系统时，就形成了像ChatGPT这样的LLM。给定一个被称为**“提示”（prompt）**的输入，LLM就擅长于生成额外的词语作为响应。 应用： 尽管LLMs的核心是预测下一个词，但它们已被许多人发现在日常工作中有用，能够帮助写作、查找基本信息或充当思维伙伴来思考问题。 </description>
    </item>
    <item>
      <title>03-无监督学习</title>
      <link>http://localhost:1313/cn/2025/04/22/unsupervised-learning/</link>
      <pubDate>Tue, 22 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/cn/2025/04/22/unsupervised-learning/</guid>
      <description>无监督学习（Unsupervised Learnning）是机器学习中，一种重要的&amp;quot;学习范式&amp;quot;。其核心是通过未标记的数据集自主学习数据中的模式、结构和规律。 与有监督学习不同，无监督学习不需要人工提供标签或明确的指导，而是通过算法自主发现数据中内在联系和潜在特征。 这种方法广泛应用于聚类、降维、异常检测等任务，是探索性数据分析的重要工具。&#xA;基础概念 无监督学习的目标是通过分析数据的内在结构，揭示数据中的隐含模式。例如，聚类算法可以将数据分为多个簇，使同一个簇中的数据相似度高，不同簇之间的数据相似度低。这种模式发现的过程不依赖预定义的标签，而是通过数据本身的特征性学习。&#xA;无监督学习的特点：&#xA;无标签数据：输入的数据没有明确的标签，模型需要自行寻找数据中的规律。 自主学习：算法通过观察数据的分布和结构，自主发现数据的潜在模式。 不确定性: 由于缺乏明确的标签，数据也存在很强的不确定性，需要人工评估。 主要方法 聚类分析 聚类分析是无监督学习中最重要的方法之一，用于将数据分为多个组或簇。常见的聚类方法包括K-means分析、层次聚类 和 密度聚类 等。&#xA;K-means：通过最小化簇内距离来划分数据点，适用于大模型数据集。 层次聚类: 通过逐步合并或分裂数据点来构建层次结构，适合小模型数据。 密度聚类：基于密度的聚类方法，将高密度区域划分为簇，适用于噪声较多的数据。 降维 降维技术旨在将高纬度的数据映射到低维空间，以减少数据的复杂性并保留关键特征。常见的方法包括主成分分析(PCA) 和 t-SNE。&#xA;关联规则学习 通过挖掘数据中的关联性，发现数据之间的依赖关系。例如，Apriori算法和Eclat算法常用于市场篮子分析等。&#xA;异常检测 识别数据集中与其他样本显著不同的异常点，用于欺诈检测、故障诊断等场景。&#xA;自监督学习 通过生成伪标签或利用数据自身作为监督信号，训练模型以完成任务。例如，自编码器用于图像生成和特征提取&#xA;应用场景 无监督学习在多个领域有广泛应用，包括：&#xA;图像处理：通过聚类和降维技术，实现图像分类、压缩和特征提取。 社交网络分析：自动发现用户群体，优化社交网络的结构和推荐系统。 市场细分：通过聚类算法，将消费者划分为不同的群体，以便更精准地进行营销。 生物信息学：用于基因表达分析、蛋白质结构预测等。 安全领域：检测网络中的异常行为，用于网络安全和欺诈检测。 无监督学习的优缺点 优点： 无需人工干预：无需人工标注数据，节省了大量时间和资源。 发现隐藏模式：能够发现数据中的复杂模式，适用于探索性数据分析。 适应性：适用于处理大规模数据集，尤其是当数据标签难以获取时。 缺点： 结果不确定性：由于缺乏明确的标签，模型结果可能需要人工评估和验证。 计算复杂度高：某些算法（如DBSCAN）在大规模数据集上运行效率较低。 缺乏评估标准：与有监督学习相比，无监督学习的评估指标较少，难以直接衡量模型的性能。 </description>
    </item>
    <item>
      <title>01-机器学习</title>
      <link>http://localhost:1313/cn/2025/04/01/machine-learning/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/cn/2025/04/01/machine-learning/</guid>
      <description>什么是机器学习 Field of study that gives computers the ability to learn without being explicitly programmed.&#xA;机器学习就是让计算机在没有明确编程的情况下学习的领域。&#xA;——Arthur Samuel (1959)&#xA;通俗的讲，机器学习是一种让计算机从数据中“学习”并做出决策的技术。它通过算法分析数据，发现其中的规律，并利用这些规律对新数据进行预测或分类。&#xA;机器学习的关键要素： 数据：机器学习的基础，包括训练数据和测试数据。 模型：用于从数据中学习规律的数学或统计模型。 算法：用于训练模型的优化方法（如梯度下降、决策树、神经网络等）。 任务：机器学习的目标，如分类、回归、聚类、降维等。 机器学习的类型： 监督学习（Supervised Learning）：使用带有标签的数据进行训练，模型学习输入与输出之间的映射关系。例如：图像分类、房价预测。&#xA;无监督学习（Unsupervised Learning）：使用无标签的数据进行训练，模型发现数据中的潜在结构或模式。例如：聚类分析、降维。&#xA;强化学习（Reinforcement Learning）：模型通过与环境的交互来学习策略，以最大化某种奖励信号。例如：游戏AI、机器人控制。&#xA;机器学习的特点 泛化能力：&#xA;机器学习的目标是让模型在未见过的数据上也能表现良好，而不仅仅是对训练数据的记忆。泛化能力是评估模型好坏的重要指标。&#xA;自动学习：&#xA;机器学习算法能够自动从数据中提取特征和规律，无需人工显式编程。 例如，在图像分类任务中，模型可以自动学习识别图像中的关键特征。&#xA;处理大数据：&#xA;机器学习依赖于大量数据作为输入，通过分析数据中的模式和规律来完成任务。数据的质量和数量直接影响模型的性能。&#xA;机器学习应用于图像识别、语音识别、自然语言处理、推荐系统、金融风控等。&#xA;应用领域： 自然语言处理（NLP） 计算机视觉（CV） 推荐系统 医疗诊断 金融风控 </description>
    </item>
    <item>
      <title>02-监督学习</title>
      <link>http://localhost:1313/cn/2025/04/01/supervised-learning/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/cn/2025/04/01/supervised-learning/</guid>
      <description>监督学习 监督学习（Supervised Learning）是机器学习中一种重要的学习范式，其核心思想是通过已知的输入-输出对（训练数据）来训练模型，使其能够对新的、未见过的输入进行准确的预测或分类。&#xA;这种学习方式的特点在于训练数据中每个样本都包含明确的标签或期望输出值，这些标签被称为“监督信号”，用于指导模型的学习过程。&#xA;监督学习定义 定义：监督学习是一种通过已知输入-输出对训练模型的方法，目标是找到一个映射函数f:X→Y，使得模型能够根据输入X 预测出相应的输出Y。&#xA;输入与输出：输入通常是一个向量（特征），而输出是一个标签或期望值。例如，在分类任务中，输出是一个离散的类别标签；在回归任务中，输出是一个连续的数值。&#xA;训练过程 数据准备：收集并标注训练数据，这些数据通常由人工标注或实际观测得到。 模型训练：通过调整模型参数，使模型能够拟合训练数据中的输入-输出关系。常见的优化目标是最小化预测值与实际值之间的误差。 模型评估：使用测试数据评估模型的性能，确保模型在未见过的数据上也能表现良好 监督学习模型训练流程示意图，展示了从输入数据到模型训练的完整过程&#xA;监督学习分类 监督学习广泛应用于各种实际问题中，包括但不限于：&#xA;分类任务 垃圾邮件检测、图像分类、语音识别等。这些任务的目标是将输入数据映射到离散的类别标签。&#xA;结构化输出 预测复杂的结构化输出，如序列标注。&#xA;回归任务 如房价预测、股票价格预测等。这些任务的目标是预测一个连续的数值输出&#xA;异常检测 如信用卡欺诈检测、设备故障预测等。这些任务的目标是识别不符合正常模式的数据&#xA;监督学习的挑战与局限性 数据标注成本高：标注数据需要大量的人力和时间投入，尤其是在复杂任务中 过拟合风险：如果模型过于复杂，可能会在训练数据上表现很好，但在新数据上表现不佳 对噪声敏感：训练数据中的噪声可能会影响模型的性能 </description>
    </item>
  </channel>
</rss>
