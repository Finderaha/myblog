---
title: "Stable Diffusion 底层逻辑"
date: 2024-10-15
author: Finder
slug: stable diffusion
draft: false
toc: true
tags: 
  - Stable Diffusion 系统课
  - ComfyUI
  - AI
---

Stable Diffusion (以下简称SD)翻译成中文是‘稳定的扩散’。的底层逻辑基于生成对抗网络（GAN）和扩散模型的理论，它的主要目标是从随机噪声中生成高质量的图像。

# 扩散算法

扩散算法的原理简单来讲就是生噪到去噪的一个过程，声噪就是增加噪点叫做正向扩散，去噪就是消除噪点，反向扩散。

在我们生图的时候，它是先把图片铺满噪点，然后根据我们的步数慢慢把噪点降噪、降噪，把噪点删除，变成一个我们想要的图片。

举个例子，假设我们想让 AI 生成"美丽女孩"的图片。首先，我们需要一个**"翻译器"（如 CLIP）**将人类语言转换为计算机可理解的数字化描述。这个过程称为文本编码。

编码后的信息进入"**latent space"（潜在空间）**。使用潜在空间的原因是为了减少计算量。直接处理一张 512 × 512 像素的图片需要计算 786,432 个数据点（512 × 512 × 3 RGB 通道），这会消耗大量算力。通过使用潜在空间，我们可以更高效地处理这些数据。它可以将数据压缩成64 × 64 × 4 = 16,384个通道，大大降低了计算成本。这就是为什么在使用Comfy UI时，我们需要将数据转换到潜在空间。

AI生成图像的过程包括添加噪声和去除噪声两个步骤。在潜在空间中，有一个叫做**"unit"的组件**，它会指导如何根据随机种子生成带噪声的图像。

<aside>
💡

随机种子是什么呢？它就像是一个起点数字。即使使用相同的关键词（比如"one girl"），每次生成的图像都会不同，这是因为每次都会随机选择一个不同的种子数字。不同的随机种子会产生不同的噪点，所以在去除噪点的过程中，我们会得到不同的图像。

</aside>

在生成图像时，我们还可以选择不同的参数，比如采样器、CFC和skill等。如果你现在不了解这些参数也不用担心，我们以后会详细解释的。

借助unit组件，图片在计算机内已经生成，但它是计算机理解的形式。对计算机来说，这些数据就是图片，但对我们人类来说，它只是一串数字，我们无法直接看懂。

接下来是最后一步：解压缩。因为之前我们压缩了数据，所以现在需要解压缩。这个过程通过**VAE解码器**完成。之前我们用编码器让计算机理解我们的语言，现在解码器则是让计算机输出我们能看懂的图像。

解码完成后，我们就能看到最终的图像了。这就是整个图像生成的过程，建议大家多次回顾以便更好地理解。
